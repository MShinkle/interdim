{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b8e132",
   "metadata": {},
   "source": [
    "# Exploring LLM Token Embeddings and Layer Activations with interdim\n",
    "\n",
    "In this notebook, we'll explore both the token embeddings and layer activations of a language model using the `interdim` package. We'll use the `transformerlens` package to load a pre-trained model, extract its token embeddings, and then examine activations from a specific layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa440a",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "**Note:** This notebook requires the `transformerlens` package as an additional dependency. You can install it by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8250a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformer-lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a0c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import transformer_lens\n",
    "from interdim import InterDimAnalysis\n",
    "from interdim.vis import InteractionPlot\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c3efd",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be50f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"pythia-14m\", device=device)\n",
    "\n",
    "# Get list of all tokenizer vocabulary\n",
    "vocab = model.tokenizer.get_vocab()\n",
    "\n",
    "# Get token IDs from vocab\n",
    "token_ids = torch.tensor(list(vocab.values()), dtype=torch.long).unsqueeze(1).to(device)\n",
    "\n",
    "# Create a list of token texts\n",
    "token_texts = [text.replace('Ä ', ' ') for text in vocab.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2ca05",
   "metadata": {},
   "source": [
    "## Part 1: Analyzing Token Embeddings\n",
    "\n",
    "First, we'll examine the token embeddings directly from the model's embedding layer. These embeddings represent the initial representation of each token before it's processed by the model's layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298227f",
   "metadata": {},
   "source": [
    "NOTE: We'll use UMAP for this demo, which requires the `umap-learn` library. You can install it via pip if you don't have it already via the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d3ef6",
   "metadata": {},
   "source": [
    "\n",
    "If you don't want to do this, you can alternatively change the `method` argument in the `reduce` to 'tsne'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce17134",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Extract token embeddings\n",
    "with torch.no_grad():\n",
    "    token_embeddings = model.embed(token_ids).squeeze(1)\n",
    "\n",
    "print(f\"Extracted embeddings for {len(vocab)} tokens with shape {token_embeddings.shape}\")\n",
    "\n",
    "# Create the InteractionPlot for text visualization\n",
    "text_plot = InteractionPlot(\n",
    "    data_source=token_texts,\n",
    "    plot_type=\"text\",\n",
    ")\n",
    "\n",
    "# Analyze token embeddings with interdim\n",
    "ida_embeddings = InterDimAnalysis(token_embeddings.cpu().numpy(), verbose=True)\n",
    "ida_embeddings.reduce(method='umap', n_components=3)\n",
    "ida_embeddings.cluster(method='birch')\n",
    "\n",
    "# Create and display the interactive plot for token embeddings\n",
    "print(\"Visualizing Token Embeddings:\")\n",
    "ida_embeddings.show(\n",
    "    n_components=3, \n",
    "    point_visualization=text_plot,\n",
    "    marker_kwargs = {\"size\": 3, \"opacity\": 0.5, \"colorscale\": 'Rainbow'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffacd312",
   "metadata": {},
   "source": [
    "### Interpreting Token Embeddings\n",
    "\n",
    "In the plot above, each point represents a token in the model's vocabulary. The spatial arrangement reflects the relationships between tokens in the embedding space, and the embeddings show how the model initially represents tokens before any contextual processing. Do you seen any clear structure?\n",
    "\n",
    "Maybe, but it's fairly weak, with individual points having some degree of similarity with nearby points. No, how do these embeddings compare to representations *within* an LLM, after they've been processed by some of the layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868197d6",
   "metadata": {},
   "source": [
    "## Part 2: Analyzing Layer Activations\n",
    "\n",
    "Now, we'll examine the activations from a specific layer of the model. This will show us how the representations of tokens change after being processed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1123b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get activations for all tokens from a specific layer\n",
    "def get_layer_activations(model, layer_name):\n",
    "    token_ids = torch.tensor(list(vocab.values()), dtype=torch.long).unsqueeze(1).to(device)\n",
    "    \n",
    "    activations = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(torch.split(token_ids, 256)):\n",
    "            _, cache = model.run_with_cache(batch)\n",
    "            batch_activations = cache[layer_name].cpu().mean(1)  # Mean over sequence length\n",
    "            activations.append(batch_activations)\n",
    "    \n",
    "    return torch.cat(activations, dim=0)\n",
    "\n",
    "# Get activations from the last layer\n",
    "layer_name = 'blocks.5.hook_resid_post'  # Adjust this for different layers\n",
    "layer_activations = get_layer_activations(model, layer_name)\n",
    "\n",
    "print(f\"Extracted activations from layer {layer_name} with shape {layer_activations.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5dbcd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Analyze layer activations with interdim\n",
    "ida_activations = InterDimAnalysis(layer_activations.numpy(), verbose=True)\n",
    "ida_activations.reduce(method='umap', n_components=3)\n",
    "ida_activations.cluster(method='birch')\n",
    "\n",
    "# Create and display the interactive plot for layer activations\n",
    "print(f\"Visualizing Layer Activations from {layer_name}:\")\n",
    "ida_activations.show(\n",
    "    n_components=3, \n",
    "    point_visualization=text_plot,\n",
    "    marker_kwargs = {\"size\": 3, \"opacity\": 0.5, \"colorscale\": 'Rainbow'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea29d25",
   "metadata": {},
   "source": [
    "### Interpreting Layer Activations\n",
    "\n",
    "This plot shows the representations of tokens after they've been processed by the model up to the specified layer. Compared to the initial embeddings, you might notice:\n",
    "\n",
    "1. Different clustering patterns\n",
    "2. More nuanced relationships between tokens\n",
    "3. Potentially clearer separation between different types of tokens\n",
    "\n",
    "By comparing the token embeddings and layer activations, we can gain insights into how the model's understanding of tokens evolves through its layers as the layers use and transform these representations.\n",
    "\n",
    "Feel free to mess around by changing layers, models, etc, and seeing how these representational spaces change!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "interdim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
